from __future__ import annotations

import contextlib
import csv
import os
import sys
import weakref
from ctypes import *
from typing import TYPE_CHECKING

import h5py
import numpy as np
from numpy import ctypeslib
from vcd import VCDWriter

from srd.internal.utils import decode, enums
from srd.internal.utils.si_prefix import si_format, si_parse
from srd.internal.utils.simulation_options import _Options_Base
from srd.internal.utils.VCD_parser import VCDparser
from srd.util.simetrix import find_simetrix_and_update_env

from .dll_wrappers import *
from .errors import *

if TYPE_CHECKING:
    from srd.exported import Analysis

INITIALISE_INTERFACE = "srd_InitialiseInterface"
# Version info for which wrapper was built - srd_InitialiseInterface entry-point
# of DLL checks this for compatibility with implementation.
MAJOR_VERSION = 1
MINOR_VERSION = 0

BIT64 = sys.maxsize > 2**32

workingdir_last_run = None


def _str_c_char_p(bytes_or_str):
    if isinstance(bytes_or_str, str):
        return c_char_p(bytes(bytes_or_str, "utf-8"))
    else:
        return c_char_p(bytes_or_str)


class Api:
    """
    Base class for simulation data access API
    """

    def __init__(self, ref_analysis, options):
        """
        Constructor
        """
        self.handle = None
        try:
            self._ref_analysis: Analysis = weakref.proxy(ref_analysis)
        except:
            self._ref_analysis: Analysis = ref_analysis

        self.simOpts = self._ref_analysis.getSimOptions()
        """:type: _Options_Base"""

        if self.simOpts.idnum is not None:
            self.ident_num = self.simOpts.idnum
        else:
            self.ident_num = 0

        self._data_valid = False

        self.simulatorSimetrix = self._ref_analysis.simulatorSimetrix
        """:type: Simetrix"""

    def __del__(self):
        self.discardloadedsimdatafiles()

    def _probe(self, name, run_num=None, cache=True, simulator=None, division_index=0):
        """
        Access probed waveform trace(s)

        :param run_num: run number in sweep, None for last run
        :type run_num: int
        :param name: name of probe whose waveform is require.
            (None = timebase reference trace)
        :type name: string
        :param cache: Cache probe data so subsequent calls for same data don't create
            more copies or trigger a SIMetrix data group load
        :type cache: bool

        :return: probed data for specified probe.
        :rtype: numpy.array
        """

        raise NotImplementedError

    def _probes(self, run_num=None, group_name=None, simulator=None):
        """
        Get list of names probe waveforms for data group/ run

        :param run_num: Run number in sweep, None for last run
        :type run_num: int
        :param group_name: Name of data-group loaded in SIMetrix
        :type group_name: string

        :rtype: list[str]
        """

        raise NotImplementedError

    def init_rundata(self):
        raise NotImplementedError

    def discardloadedsimdatafile(self, run_num, check_loaded=True):
        """
        Discard probe data group from SIMetrix

        Normally a probed Data group accessed via probe is kept loaded in SIMetrix
        memory to avoid having to (expensively) reload it if further probed data vectors
        are accessed.  Calling this forces it to be unloaded from SIMetrix free-ing up
        memory.  Of course a follow-in accesses will be slow/expensive as data group
        needs to be reloaded.

        :param run_num: Run number in sweep, None for last run
        :type run_num: int
        :param check_loaded: Check group is actually loaded in SIMetrix, do nothing if it is not
        :type check_loaded: bool
        """
        raise NotImplementedError

    def discardloadedsimdatafiles(self):
        """
        discard all   data groups currently loaded into SIMetrix
        """
        # print("DISCARD...")
        raise NotImplementedError

    def refreshLoadedDataGroups(self):
        """
        Update local view of probe data groups currently loaded in SIMetrix

        Refresh  table of data groups loaded into SIMetrix from
        SIMetrix internal list.  Used to re-sync if
        activity in SIMetrox may have caused data groups loaded to change.
        """
        raise NotImplementedError

    def write_sim_data_file(self):
        """
        Writes simulation data in specific format of the API
        """
        raise NotImplementedError


class ApiSimetrix(Api):
    """
    API for SIMetrix remote data access

    C functions exposed by SIMetrix data access DLL, wrapped to return
    results in native Python formats and raise exceptins for error returns.

    :param idnum: SIMetrix instance id number (0 - default/1st)
    :type idnum: int
    """

    # Remote Data interface is automatically opened when Api is constructed

    class GroupInfo:
        """
        Information about data vector group assumed to be loaded into
        SIMetrix.  `run_id`  is crucial as SIMetrix re-uses group-names...
        """

        def __init__(self, name=None, run_id=None):
            self.name = name
            self.run_id = run_id

        def __repr__(self):
            return rf"SRD.Analysis.GroupInfo({self.name}, {self.run_id})"

        def __str__(self):
            return rf"SRD.Analysis.GroupInfo({self.name}, {self.run_id})"

    def __init__(self, ref_analysis, options):
        """
        Constructor

        :param options: An object describing the analysis- and simulator-dependent settings.
        :type options: ..utils.simulation_options._Options_Base
        """

        Api.__init__(self, ref_analysis, options)
        #
        # SIMETRIX remote data interface DLL sxrdif.dll handle
        #
        self.sxrdif = None

        #
        # SIMetrix remote data interface wrapper - function pointer struct
        #
        self.srd_ifc = None

        if self.sxrdif is None:
            simetrix_install = find_simetrix_and_update_env()
            self.sxrdif = WinDLL(str(simetrix_install / "bin64" / "sxrdif"))

        if self.srd_ifc is None:
            InitialiseInterfacePrototype = CFUNCTYPE(ErrorCode, POINTER(Interface), POINTER(c_int), POINTER(c_int))
            srd_InitialiseInterface = InitialiseInterfacePrototype((INITIALISE_INTERFACE, self.sxrdif))
            major = c_int(MAJOR_VERSION)
            minor = c_int(MINOR_VERSION)
            self.srd_ifc = Interface()

            res = srd_InitialiseInterface(byref(self.srd_ifc), byref(major), byref(minor))
            self.check_res_ok(res, INITIALISE_INTERFACE)

        # print("ADDR openInterface: %x" % srd_ifc.openInterface)
        self.ff_openInterface = Interface.openInterfacePrototype(self.srd_ifc.openInterface)
        self.ff_closeInterface = Interface.closeInterfacePrototype(self.srd_ifc.closeInterface)
        self.ff_getGroupNames = Interface.getGroupNamesPrototype(self.srd_ifc.getGroupNames)
        self.ff_getVectorInfo = Interface.getVectorInfoPrototype(self.srd_ifc.getVectorInfo)
        self.ff_getVectorData = Interface.getVectorDataPrototype(self.srd_ifc.getVectorData)
        self.ff_destroyData = Interface.destroyDataPrototype(self.srd_ifc.destroyData)

        # List of names/run_ids of data groups in SIMetrix
        self.__groupinfos = {}
        """:type : dict[int, Simetrix.GroupInfo]"""

        # List of dictionaries containing probename-probevalue pairs for each data group (one dict per sweep point)
        self.probe_caches = []
        """:type : list[dict[str, object]]"""

        self.handle = None

    def __del__(self):
        """
        Destructor

        Remote Data interface is automatically closed when Api is destructed
        """
        self.closeDataLink()

    @property
    def groupinfos(self):
        return self.__groupinfos

    @groupinfos.setter
    def groupinfos(self, value):
        """
        Holds information on group names and simulation runs performed with simulator object.
        """
        self.__groupinfos = value

    def init_rundata(self):
        self.discardloadedsimdatafiles()
        self.probe_caches = [{} for _ in next(iter(self.simOpts.sim_params.items()))[1]]
        self._data_valid = True
        for i in range(self.simOpts.runs):
            self.groupinfos.update({i: None})

    def _link_open(self):
        """
        Open link to SIMetrix if not currently open
        """
        if self.handle is not None:
            return

        ident = c_int(self.ident_num)
        self.handle = c_void_p(0)
        res = self.ff_openInterface(ident, byref(self.handle))
        if res != E.Ok:
            self.handle = None
        self.check_res_ok(res, "openInterface")

    def closeDataLink(self):
        """
        Close link to SIMetrix
        """
        if self.handle is None:
            return
        res = self.ff_closeInterface(self.handle)
        self.handle = None
        self.check_res_ok(res, "closeInterface")

    def check_res_ok(self, code, context=None):
        if code != E.Ok:
            raise IFCERRCodeError(code, context)

    def getGroupNames(self):
        """
        Get list of names of available  "data groups" in SIMetrix

        For example, by default, after a single transient run of a
        freshly started SIMetrix we would expect SRD to return
        ``[ 'global', 'tran1' ]``

        :return: Names of available data groups
        :rtype: list[str]
        """

        self._link_open()
        name_strings_p = POINTER(Strings)()
        res = self.ff_getGroupNames(self.handle, byref(name_strings_p))

        self.check_res_ok(res, "getGroupNames")
        groupnames = []
        for g in range(name_strings_p.contents.numStrings):
            groupnames.append(name_strings_p.contents.strings[g][:])
        self.ff_destroyData(self.handle, name_strings_p)
        return groupnames

    def getVectorInfo(self, groupname, vecname=None):
        """
        Fetch information about data vector / all vectors in a group

        :param groupname: Data group of required vector
        :type groupname: string
        :param vecname: Vector for which information is to be fetech (None/ommitted
           means 'all vectors'
        :type vecname: string

        .. note:: Currently no support for setting the option to
        return operating point

        """

        self._link_open()
        options = Options()
        options.opMode = O_None
        vecinfo_array_p = POINTER(VectorInfoArray)()
        res = self.ff_getVectorInfo(
            self.handle, _str_c_char_p(groupname), vecname, byref(options), byref(vecinfo_array_p)
        )
        self.check_res_ok(res, "getVectorInfo")
        num_elems = vecinfo_array_p.contents.numElems
        vi = vecinfo_array_p.contents.vectorInfo
        res = []
        for idx in range(num_elems):
            refName = vi[vi[idx].refIndex].name[:] if vi[idx].refIndex >= 0 and vi[idx].refIndex < num_elems else ""
            resdict = {
                "name": vi[idx].name[:],
                "dataType": vi[idx].dataType,
                "totalLength": vi[idx].totalLength,
                "numDivisions": vi[idx].numDivisions,
                "physTypeName": vi[idx].physTypeName[:],
                "refName": refName,
            }
            res.append(resdict)

        self.ff_destroyData(self.handle, vecinfo_array_p)
        return res

    def getVectorData(self, groupname, vectorname, nogroup_ok, option=V.XY, offset=0, division=0):
        """
        Fetch raw ctypes data vector data

        :param groupname: Data group  of required vector
        :type groupname: str
        :param vectorname: Name vector to be fetched from group `groupname`
        :type vectorname: str
        :param nogroup_ok: Return None rather than exception if specifed data
            group not loaded in SIMetrix
        :type nogroup_ok: bool
        :param option: See `SRD.V` and `SRD.Options.dataOptions`
        :type option: { V.XY, V.X, V.Y }
        :param offset: Offset from vector data to be returned see `SRD.Options.offset`
        :type offset: int
        :param division: For multi-div vectors division to access (see `SRD.Options.division`)
        :type division: int

        :return: length of vector data array
        :rtype: int
        :return: ptr 1st elt of of specified vector (Y) data (if option not `V.Y`)
        :rtype: ctypes.POINTER(c_double)
        :return: 1st elt of specified vector ref (X) data (if option is `V.X` or `V.XY`)
        :rtype: ctypes.POINTER(c_double)
        :return: Datatype of returned vector data
        :rtype: SRD.D enum value

        .. note:: Can return None if  specifed datagroup not loaded in SIMetrix
        """

        self._link_open()
        vector_data_p = POINTER(VectorData)()
        options = Options()
        options.dataOptions = option
        options.offset = offset
        options.divisionIndex = division

        res = self.ff_getVectorData(
            self.handle, _str_c_char_p(groupname), _str_c_char_p(vectorname), byref(options), byref(vector_data_p)
        )
        if nogroup_ok and res == E.NoGroup:
            return None
        self.check_res_ok(res, "getVectorData")
        ref = None
        data = None
        if options.dataOptions == V.Y or options.dataOptions == V.XY or options.dataOptions == V.AliasLiterals:
            if vector_data_p.contents.dataType == D.Real:
                data = vector_data_p.contents.d.realData
            elif vector_data_p.contents.dataType == D.Complex:
                data = vector_data_p.contents.d.complexData
            elif vector_data_p.contents.dataType == D.String:
                data = vector_data_p.contents.d.stringData

        if options.dataOptions == V.X or options.dataOptions == V.XY:
            ref = vector_data_p.contents.refData
        return vector_data_p.contents.numElems, data, ref, vector_data_p.contents.dataType, vector_data_p

    def getStringVector(self, groupname, vectorname, offset=0, division=0):
        """
        Get SIMetrix string vector as python string array
        """

        vecdata = self.getVectorData(groupname, vectorname, False, option=V.Y, offset=offset, division=division)

        if vecdata is None:
            msg = f"{groupname}:{vectorname} has no data"
            raise UsageError(msg)
        (num_elems, data, _, datatype, _) = vecdata

        if datatype == D.String:
            res = []
            for i in range(num_elems):
                res.append(data[i][:])
            return res
        else:
            msg = f"{groupname}:{vectorname} is not string vector"
            raise UsageError(msg)

    def getRunID(self, groupname):
        """
        Get run id stamp from specified group

        :return: Run id  if accesible and defined otherwise None
        :rtype: int | None
        """
        try:
            vecdata = self.getVectorData(groupname, r"$$RunId", False, option=V.Y, offset=0, division=0)
            if vecdata is None:
                # print("No data:", groupname + r':$$RunId')
                return None
            (num_elems, data, _, datatype, _) = vecdata
            if datatype == D.Real and num_elems > 0:
                return data[0]
            else:
                # print("Not non-empty realvec: ", groupname + r':$$RunId')
                return None
        except:
            # print("No access: ", groupname + r':$$RunId')
            return None

    def getNumpyVector(self, groupname, vectorname, nogroup_ok, offset=0, division=0):
        """
        Fetch data vector data as Numpy vector (Double ndarray f shape (N,))

        Currently only supports data vectors of SRD_Real type,
        (no SRD_Complex or SRD_String).

        :param groupname: Data group to of required vector
        :type groupname: str
        :param vectorname: Vector to be fetched
        :type vectorname: str
        :param nogroup_ok: Return None rather than exception if specifed data
            group not loaded in SIMetrix
        :type nogroup_ok: bool
        :param offset: Offset from vector data to be returned `SRD.Options.offset`
        :type offset: int
        :param division: For multi-div vectors. >= 0 `SRD.Options.division`
        :type division: int

        :rtype: VectorData
        """

        vecdata = self.getVectorData(groupname, vectorname, nogroup_ok, option=V.Y, offset=offset, division=division)
        if vecdata is None:
            return None
        (num_elems, data, _, datatype, vector_data_p) = vecdata
        if datatype == D.Real:
            numpy_vec = np.array(ctypeslib.as_array(data, (num_elems,)), copy=True)
        elif datatype == D.Complex:
            numpy_vec = np.zeros(num_elems, dtype=np.complex)
            for j in range(num_elems):
                simetrix_complex = data[j]
                numpy_vec[j] = np.complex(simetrix_complex.real, simetrix_complex.imag)
        else:
            res = self.ff_destroyData(self.handle, vector_data_p)
            self.check_res_ok(res, "destroyData")
            msg = f"Unsupported: Vectors of type SRD_D{D.names(datatype)}"
            raise NumpyIfcError(msg)
        res = self.ff_destroyData(self.handle, vector_data_p)
        self.check_res_ok(res, "destroyData")
        return numpy_vec

    def printVectorInfo(self, groupname, vecname=None):
        """
        Print vector info for all/specified vector (debug utility)

        :param groupname: Data group to of required vector
        :type groupname: str
        :param vecname: Vector to be printed  (None/ommitted means 'All vectors')
        :type vecname: str
        """
        vi = self.getVectorInfo(groupname, vecname)
        for info in vi:
            print(
                "%30s: dataType=%d, len=%6d, numdiv=%d, phystype=%12s, ref=%s"
                % (
                    info["name"],
                    info["dataType"],
                    info["totalLength"],
                    info["numDivisions"],
                    info["physTypeName"],
                    info["refName"],
                )
            )

    def printAllGroupsVectorInfo(self, vecname=None):
        """
        Print VectorInfo for vector(s) in all data groups (debug utility)

        :param vecname: Vector to be printed  (None/ommitted means 'All vectors')
        :type vecname: str
        """
        g = 0
        group_names = self.getGroupNames()
        print("Number of groups: %d" % len(group_names))
        for g, groupname in enumerate(self.getGroupNames()):
            print("\ngroup[%d] = %s" % (g, groupname))
            self.printVectorInfo(groupname, vecname)

    def printVectorData(self, groupname, vectorname, option=V.XY, offset=0, division=0):
        """
        Print VectorData for specified vector  (debug utility)

        :param groupname: Data group to of required vector
        :type groupname: str
        :param vectorname: Vector to be fetched
        :type vectorname: str
        :param nogroup_ok: Return None rather than exception if specifed data
            group not loaded in SIMetrix
        :type nogroup_ok: bool
        :param offset: Offset from vector data to be returned `SRD.Options.offset`
        :type offset: int
        :param division: For multi-div vectors. >= 0 `SRD.Options.division`
        :type division: int
        """
        (num_elts, data, ref, _, _) = self.getVectorData(groupname, vectorname, option, offset, division)
        for i in range(num_elts):
            print(
                f"{i:8d}: {data[i]}",
            )
            if ref is not None:
                print(f"{ref[i]}")
            else:
                print()

    def _probe(self, name, run_num=None, cache=True, simulator=None, division_index=0):
        """
        Access probed waveform trace(s)

        :param run_num: Run number in sweep, None for last run
        :type run_num: int
        :param name: Name of probe whose waveform is require.
            (None = timebase reference trace)
        :type name: str
        :param cache: Cache probe data so subsequent calls for same data don't create
            more copies or trigger a SIMetrix data group load
        :type cache: bool

        :return: probed data for specified probe.
        :rtype: numpy.array
        """

        run_num = self.simOpts._default_run_num(run_num)

        if not self._data_valid:
            msg = "No data available (no succesful simulation run / dataset open)"
            raise NumpyIfcError(msg)

        try:
            run_cache = self.probe_caches[run_num]
        except IndexError:  # If PyVerify single run: run_num may be bigger than len(self.probe_caches)
            run_cache = []
            cache = False
        if name not in run_cache:
            # Fetch data. A loaded group may have been flushed by SIMetrix
            # so its o.k. to have to retry the fetch after reloading
            data = self.getNumpyVector(self.loadedDataGroup(run_num), name, nogroup_ok=True, division=division_index)
            if data is None:
                self.refreshLoadedDataGroups()
                data = self.getNumpyVector(
                    self.loadedDataGroup(run_num), name, nogroup_ok=False, division=division_index
                )
            if cache:
                # Cached - make it read-only to prevent nasty overwriting bugs
                data.setflags(write=False)
                run_cache[name] = data

        else:
            data = run_cache[name]
        return data

    def _probes(self, run_num=None, group_name=None, simulator=None, full_data=None):
        """
        Get list of names probe waveforms for data group/ run

        :param run_num: Run number in sweep, None for last run
        :type run_num: int
        :param group_name: Name of data-group loaded in SIMetrix
        :type group_name: str
        :param simulator: Name of simulator used
        :type group_name: str
        :param full_data: Probes return full data of all probes, e.g. type of probe
        :type group_name: bool

        :rtype:list[str]
        """

        if not self._data_valid:
            msg = "No data available (no succesful simulation run / dataset open)"
            raise NumpyIfcError(msg)

        run_num = self.simOpts._default_run_num(run_num)
        if group_name is None:
            group_name = self.loadedDataGroup(run_num)

        vecinfos = self.getVectorInfo(group_name, None)
        if full_data:
            return vecinfos
        else:
            return [vi["name"] for vi in vecinfos]

    def path_for_sim_result_file(self, run_num):
        return os.path.join(self.simOpts.workingdir, f"{self.simOpts.fileprefix}_{run_num:04d}.sxdat")

    def discardloadedsimdatafile(self, run_num, check_loaded=True):
        """
        Discard probe data group from SIMetrix

        Normally a probed Data group accessed via probe is kept loaded in SIMetrix
        memory to avoid having to (expensively) reload it if further probed data vectors
        are accessed.  Calling this forces it to be unloaded from SIMetrix free-ing up
        memory.  Of course a follow-in accesses will be slow/expensive as data group
        needs to be reloaded.

        :param run_num: Run number in sweep, None for last run
        :type run_num: int
        :param check_loaded: Check group is actually loaded in SIMetrix, do nothing if it is not
        :type check_loaded: bool
        """
        if run_num < len(self.probe_caches):
            self.probe_caches[run_num] = {}
        else:
            self.probe_caches[0] = {}
        if run_num in self.groupinfos:
            groupinfo = self.groupinfos[run_num]
            self.groupinfos[run_num] = None
            if groupinfo is None:
                return
            if check_loaded and groupinfo.name not in self.getGroupNames():
                return

            discardcommand = r"DelGroup /noDelete " + decode(groupinfo.name)
            # print("DELGROUP: ", groupinfo.name)
            res = self.simulatorSimetrix.simetrixCmd(discardcommand, idnum=self.simOpts.idnum)
            if res != 0:
                raise SxCmdERRCodeError(res, discardcommand, "Failed to discard datagroup!")

    def discardloadedsimdatafiles(self):
        """
        Discard all data groups currently loaded into SIMetrix.
        """
        # print("DISCARD...")
        self.refreshLoadedDataGroups()
        for run in range(len(self.groupinfos)):
            self.discardloadedsimdatafile(run, check_loaded=False)

    def closeDataGroups(self):
        """
        Close all loaded datagroups and shut-down link to SIMetrix.
        """
        # print("CLOSING...")
        self.closeDataLink()

    def loadedDataGroup(self, run_num):
        """
        Demand-load probe data for specific run

        If not already  loaded, load probed data group of run @c run_num last
        last loaded/succesfully run simulation (sweep).

        .. note:: This is a private/internal routine and so does not check run_num
        for plausibility!

        :param run_num: Number of run in sweep whose data-group
        :type run_num: int
        :return: Name assigned to data-group holding loaded probe data
        :rtype: str
        """

        run_num = self.simOpts._default_run_num(run_num)

        if run_num in self.groupinfos:  # If PyVerify single run: run_num may be bigger than len(self.probe_caches)
            groupinfo = self.groupinfos[run_num]
            # Group has been loaded and has not been over-written in the meantime..
            if groupinfo is not None:
                run_id_probed = self.getRunID(groupinfo.name)
                if groupinfo.run_id == run_id_probed:
                    return groupinfo.name

        absdatagroupfilename = self.path_for_sim_result_file(run_num)
        # Explanation:  in SIMetrix 7.10 this does NOT actually seem to
        # over-write as suggested  in documentation it just suppresses the info
        # message that a renaming has taken place to avoid an over-write.
        # This is actually preferrable behaviour (no 'surprize' changes to data)
        loadcommand = r'OpenGroup /overwrite "' + absdatagroupfilename + r'"'
        res = self.simulatorSimetrix.simetrixCmd(loadcommand, idnum=self.simOpts.idnum)
        if res != 0:
            raise SxCmdERRCodeError(res, loadcommand, "Failed to load datagroup!")

        # Loaded data group automatically becomes the current one
        groupinfo = self.GroupInfo()
        groupinfo.name = self.getCurGroup()
        groupinfo.run_id = self.getRunID(groupinfo.name)
        self.groupinfos[run_num] = groupinfo
        return groupinfo.name

    def refreshLoadedDataGroups(self):
        """
        Update local view of probe data groups currently loaded in SIMetrix

        Refresh  table of data groups loaded into SIMetrix from
        SIMetrix internal list.  Used to re-sync if
        activity in SIMetrox may have caused data groups loaded to change.
        """
        simetrix_groups = set(self.getGroupNames())
        for run, groupinfo in self.groupinfos.items():
            if groupinfo is not None:
                invalidate = False
                if groupinfo.name not in simetrix_groups or groupinfo.run_id != self.getRunID(groupinfo.name):
                    invalidate = True

                if invalidate:
                    # print("INVALIDATING: ", groupinfo)
                    if run < len(self.probe_caches):
                        self.probe_caches[run] = {}
                    else:
                        self.probe_caches[0] = {}
                    if run in self.groupinfos:
                        self.groupinfos[run] = None

    def getCurGroup(self):
        """
        Get Name of Data group currently to use as default.
        """
        group_names = self.getGroupNames()
        return group_names[-1]

    def convert_sim_data(self, indexes=None):
        data = {}
        for idx in indexes:
            probes = self._probes(run_num=idx, full_data=True)
            for probe in probes:
                name = probe["name"]
                type = probe["dataType"]
                if type == 0 and b"$$" not in name:
                    # Only use vectors which are type 0 (real) and starting not with "$$" which is also not a valid probe vector
                    data[name.decode().lower()] = self._probe(name=name, run_num=idx)
            if self.simOpts.simdata_format == enums.SimulationDatatype.CSV:
                api = ApiCSV(ref_analysis=self._Api_ref_analysis, options=self.simOpts)
            elif self.simOpts.simdata_format == enums.SimulationDatatype.VCD:
                api = ApiVCD(ref_analysis=self._Api_ref_analysis, options=self.simOpts)
            api.write_sim_data_file(data=data, id=idx)


class ApiHDF5(Api):
    """
    API for HDF5 remote data access

    """

    def __init__(self, ref_analysis, options):
        """
        Constructor
        """
        Api.__init__(self, ref_analysis, options)

        # List of dictionaries containing probename-probevalue pairs for each simulation run (one dict per sweep point)
        self.probe_caches = []
        """:type : list[dict[str, list[]]]"""

        # HDF5 file handle
        self.hdf5_handle = {}
        """:type: dict[str,h5py.File]"""

    def __del__(self):
        """
        Destructor

        Remote Data interface is automatically closed when Api is destructed
        """

    def init_rundata(self):
        self.probe_caches = [{} for _ in next(iter(self.simOpts.sim_params.items()))[1]]
        self._data_valid = True

    def path_for_sim_result_file(self, run_num, simulator):
        # Setup Simulation Result file names
        if self.simOpts._opts_container["analysis"] == enums.AnalysisType.TRAN:
            output_hdf5_suffix = enums.TitanSuffix.Tran_HDF5
        elif self.simOpts._opts_container["analysis"] == enums.AnalysisType.DC:
            output_hdf5_suffix = enums.TitanSuffix.DC_HDF5
        elif self.simOpts._opts_container["analysis"] == enums.AnalysisType.AC:
            output_hdf5_suffix = enums.TitanSuffix.AC_HDF5
        else:
            msg = "Selected Analysis is not supported: {}".format(self.simOpts._opts_container["analysis"])
            raise ValueError(msg)
        h5_path = os.path.join(self.simOpts.workingdir, f"{self.simOpts.fileprefix}_{run_num:04d}{output_hdf5_suffix}")
        h5_path_compressed = h5_path + r"_c"
        if os.path.isfile(h5_path_compressed):
            return h5_path_compressed
        elif os.path.isfile(h5_path):
            return h5_path
        else:
            msg = (
                "There is no HDF5 file available in the selected workingdir. Expected file path "
                f"would be: {h5_path} or {h5_path_compressed}"
            )
            raise FileExistsError(msg)

    def fetch_simdata(self, file_handle, name):
        """
        Load HDF5 signals and store as dictionary.

        The default HDF5 file is a compressed version with multirate enabled.
        As a legacy support, also the old non-compressed format can be read.

        :param file_handle: Handle to selected hdf5 file
        :type file_handle: h5py.File
        :param name: Signal name
        :type name: str

        :return: Dict of numpy arrays (keys are column titles, values are column values)
        :rtype:dict[numpy.array]
        """

        sweep_group = file_handle["Root/SWEEP0"]
        if sweep_group.attrs.get("SingleRate") == enums.HDF5Bool.FALSE:
            if name.lower() == "Time".lower():
                h5_data = file_handle.get("/".join(["Root", "SWEEP0", "X-axis"]), default=False)
            else:
                h5_key_list = list(file_handle["/".join(["Root", "SWEEP0"])].keys())
                h5_key_list_upper = list(map(str.upper, h5_key_list))
                name = h5_key_list[h5_key_list_upper.index(name.upper())]
                data_sig = file_handle.get("/".join(["Root", "SWEEP0", name, "Y-axis"]))

                # Interpolate Simulation data (data_sig) with corresponding time vector (time_sig) according to time_ref axis
                time_ref = file_handle.get("/".join(["Root", "SWEEP0", "X-axis"]), default=False)
                time_sig = file_handle.get("/".join(["Root", "SWEEP0", name, "X-axis"]))
                h5_data = np.interp(x=time_ref, xp=time_sig, fp=data_sig)

        elif sweep_group.attrs.get("SingleRate") == enums.HDF5Bool.TRUE:
            if name.lower() == "Time".lower():
                h5_data = file_handle.get("/".join(["Root", "SWEEP0", "X-axis"]), default=False)
            else:
                h5_key_list = list(file_handle["/".join(["Root", "SWEEP0"])].keys())
                h5_key_list_upper = list(map(str.upper, h5_key_list))
                name = h5_key_list[h5_key_list_upper.index(name.upper())]
                h5_data = file_handle.get("/".join(["Root", "SWEEP0", name, "Y-axis"]))
        else:
            msg = "the HDF5 file specified is no valid SRD format."
            raise AttributeError(msg)
        if h5_data is None:
            msg = f"the Signal {name} is not available in the selected HDF5 File."
            raise ValueError(msg)
        return np.array(h5_data)

    def setup_data_access(self, run_num, simulator):
        if not self._data_valid:
            msg = "No data available (no succesful simulation run / dataset reload)"
            raise UsageError(msg)

        if simulator is None:
            simulator = self.simOpts._opts_container["simulator"]

        if simulator not in enums.SimulatorType.__dict__:
            msg = f"Specified Simulator is not valid. Valid simulators are: {enums.SimulatorType}; given simulator was: {simulator}"
            raise UsageError(msg)

        hdf5_handle = "_".join([simulator, str(run_num)])
        hdf5_file_name = self.path_for_sim_result_file(run_num, simulator)
        if hdf5_handle not in self.hdf5_handle:
            self.hdf5_handle[hdf5_handle] = h5py.File(hdf5_file_name, "r")
        return self.hdf5_handle[hdf5_handle]

    def _probe(self, name, run_num=None, cache=True, simulator=None, division_index=0):
        """
        Access csv logfile data for specified run number simulation parameter

        :param run_num: Run number in sweep, omit/None for last run, 'all' for all runs
        :type run_num: int
        :param name: Column name in csv log, omit/None for all
        :type name: str

        :return: dict for `run_num`only or specified,
            list  for `name`  only specified,
            numpy.array for specified `run_num` and `name`,
            list of dict for run_num='all' specified
        :rtype: numpy.array | list[numpy.array] | dict[ string : numpy.array]
        """

        run_num = self.simOpts._default_run_num(run_num)
        hdf5_handle = self.setup_data_access(run_num, simulator)

        try:
            run_cache = self.probe_caches[run_num]
        except IndexError:  # If PyVerify single run: run_num may be bigger than len(self.probe_caches)
            run_cache = []
            cache = False

        if name not in run_cache:
            data = self.fetch_simdata(hdf5_handle, name)
            if cache:
                # Cached - make it read-only to prevent nasty overwriting bugs
                data.setflags(write=False)
                run_cache[name] = data

        else:
            data = run_cache[name]
        return data

    def _probes(self, run_num=None, group_name=None, simulator=None):
        """
        Get list of names probe waveforms for specified run

        :param run_num: Run number in sweep, omit/None for last run, 'all' for all runs
        :type run_num: int

        :rtype:list[str]
        """
        run_num = self.simOpts._default_run_num(run_num)
        hdf5_handle = self.setup_data_access(run_num, simulator)

        sweep_group = hdf5_handle["Root/SWEEP0"]
        signal_names = []
        for name in sweep_group:
            if name != "X-axis":
                signal_names.append(name)
        return signal_names

    def discardloadedsimdatafiles(self):
        """ """
        for key in self.hdf5_handle:
            hdf5_handle = self.hdf5_handle[key]
            with contextlib.suppress(Exception):
                hdf5_handle.close()
        self.hdf5_handle = {}

    def refreshLoadedDataGroups(self):
        """
        Update local view of probe data groups currently loaded in SIMetrix

        Refresh  table of data groups loaded into SIMetrix from
        SIMetrix internal list.  Used to re-sync if
        activity in SIMetrox may have caused data groups loaded to change.
        """


class ApiCSV(Api):
    """
    API for CSV remote data access
    """

    def __init__(self, ref_analysis, options):
        """
        Constructor
        """
        Api.__init__(self, ref_analysis, options)

        # List of dictionaries containing probename-probevalue pairs for each simulation run (one dict per sweep point)
        self.probe_caches = []
        """:type : list[dict[str, list[]]]"""

    def __del__(self):
        """
        Destructor

        Remote Data interface is automatically closed when Api is destructed
        """

    def init_rundata(self):
        self.probe_caches = [None] * self.simOpts.runs
        self._data_valid = True

    def path_for_sim_result_file(self, run_num):
        return os.path.join(self.simOpts.workingdir, f"{self.simOpts.fileprefix}_{run_num:04d}.csv")

    def _probe(self, name, run_num=None, cache=True, simulator=None, division_index=0):
        """
        Access csv logfile data for specified run number simulation parameter

        :param run_num: Run number in sweep, omit/None for last run, 'all' for all runs
        :type run_num: int
        :param name: Column name in csv log, omit/None for all
        :type name: str

        :return: dict for `run_num`only or specified,
            list  for `name`  only specified,
            numpy.array for specified `run_num` and `name`,
            list of dict for run_num='all' specified
        :rtype: numpy.array | list[numpy.array] | dict[ string : numpy.array]
        """

        if not self._data_valid:
            msg = "No data available (no succesful simulation run / dataset reload)"
            raise UsageError(msg)

        run_num = self.simOpts._default_run_num(run_num)

        if run_num == "all":
            for r in range(len(self.probe_caches)):
                if self.probe_caches[r] is None:
                    self.probe_caches[r] = self.self.fetch_simdata(self.path_for_sim_result_file(r))
        else:
            if self.probe_caches[run_num] is None:
                self.probe_caches[run_num] = self.self.fetch_simdata(self.path_for_sim_result_file(run_num))

        if run_num == "all" and name is None:
            return self.probe_caches

        if run_num != "all" and run_num >= len(self.probe_caches):
            raise UsageError("Run number must be in range [0 .. %d]" % len(self.probe_caches))

        if name is not None and run_num != "all" and name not in self.probe_caches[run_num]:
            print("No such  name in simulation log: ", name)
            print("Available names: ", self.probe_caches[run_num].keys())
            raise UsageError("Bad probe name " + name)

        if name is None:
            return self.probe_caches[run_num]

        if run_num == "all":
            if name not in self.probe_caches[0]:
                print("No such  name in simulation log: ", name)
                print("Available names: ", self.probe_caches[0].keys())
                raise UsageError("Bad probe name " + name)
            return [log[name] for log in self.probe_caches]

        if name not in self.probe_caches[run_num]:
            print("No such  name in simulation log: ", name)
            print("Available names: ", self.probe_caches[run_num].keys())
            raise UsageError("Bad probe name " + name)

        return self.probe_caches[run_num][name]

    def fetch_simdata(self, csv_logfile):
        """
        Load simdata file as dictionary

        :return: Dict of numpy arrays (keys are column titles, values are column values)
        :rtype: dict[numpy.array]
        """

        with open(csv_logfile) as csvfile:
            csvstrm = csv.DictReader(csvfile, delimiter=";", quotechar='"')

            rowdict = next(csvstrm)
            csvdict = {name: [float(value)] for name, value in rowdict.items()}

            for rowdict in csvstrm:
                for name, value in rowdict.items():
                    csvdict[name].append(float(value))
        return {name: np.array(value) for name, value in csvdict.items()}

    def _probes(self, run_num=None, group_name=None, simulator=None):
        """
        Get list of names probe waveforms for specified run

        :param run_num: Run number in sweep, omit/None for last run, 'all' for all runs
        :type run_num: int

        :rtype:list[str]
        """

        if not self._data_valid:
            msg = "No data available (no succesful simulation run / dataset open)"
            raise NumpyIfcError(msg)

        run_num = self.simOpts._default_run_num(run_num)

        if self.probe_caches[run_num] is None:
            self.probe_caches[run_num] = self.self.fetch_simdata(self.path_for_sim_result_file(run_num))

        return self.probe_caches[run_num].keys()

    def refreshLoadedDataGroups(self):
        """
        Update local view of probe data groups currently loaded in SIMetrix

        Refresh  table of data groups loaded into SIMetrix from
        SIMetrix internal list.  Used to re-sync if
        activity in SIMetrox may have caused data groups loaded to change.
        """

    def write_sim_data_file(self, data=None, id=None):
        """
        Creates new sim data file with respective file format
        """
        file = self.path_for_sim_result_file(run_num=id)
        header = data.keys()

        with open(file, "w", newline="") as f:
            writer = csv.writer(f)
            writer.writerow(header)
            # writes data with transformed vectors in order to write each vector from up to down instead from left to right
            writer.writerows(zip(*data.values()))


class ApiVCD(Api):
    def __init__(self, ref_analysis, options):
        """
        Constructor for VCD reader.
        """
        Api.__init__(self, ref_analysis, options)

        # List of dictionaries containing probename-probevalue pairs for each simulation run (one dict per sweep point)
        self.probe_caches = []
        """:type : list[dict[str, list[]]]"""

        # VCD file handle
        self.vcd_handle = {}
        """:type: dict[str,vcd.VCDparser]"""

    def __del__(self):
        """
        Destructor

        Remote Data interface is automatically closed when Api is destructed
        """

    def init_rundata(self):
        self.probe_caches = [{} for _ in next(iter(self.simOpts.sim_params.items()))[1]]
        self._data_valid = True

    def _probe(self, name, run_num=None, cache=True, simulator=None, division_index=0):
        """
        Access vcd data for specified run number simulation parameter

        :param run_num: Run number in sweep, omit/None for last run, 'all' for all runs
        :type run_num: int
        :param name: Column name in csv log, omit/None for all
        :type name: str

        :return: dict for `run_num`only or specified,
            list  for `name`  only specified,
            numpy.array for specified `run_num` and `name`,
            list of dict for run_num='all' specified
        :rtype: numpy.array | list[numpy.array] | dict[ string : numpy.array]

        """
        run_num = self.simOpts._default_run_num(run_num)
        vcd_handle = self.setup_data_access(run_num, simulator)
        try:
            run_cache = self.probe_caches[run_num]
        except IndexError:  # If PyVerify single run: run_num may be bigger than len(self.probe_caches)
            run_cache = []
            cache = False

        if name not in run_cache:
            data = self.fetch_simdata(vcd_handle, name)
            if cache:
                # Cached - make it read-only to prevent nasty overwriting bugs
                data.setflags(write=False)
                run_cache[name] = data

        else:
            data = run_cache[name]
        return data

    def _probes(self, run_num=None, group_name=None, simulator=None):
        """
        Get list of names probe waveforms for specified run

        :param run_num: Run number in sweep, omit/None for last run, 'all' for all runs
        :type run_num: int

        :rtype:list[str]
        """
        run_num = self.simOpts._default_run_num(run_num)
        vcd_handle = self.setup_data_access(run_num, simulator)
        return vcd_handle.list_sigs()

    def discardloadedsimdatafiles(self):
        """ """
        for key in self.vcd_handle:
            vcd_handle = self.vcd_handle[key]
            with contextlib.suppress(Exception):
                del vcd_handle
        self.vcd_handle = {}

    def setup_data_access(self, run_num, simulator):
        """

        :param run_num:
        :param simulator:
        :rtype: VCDparser
        """
        if not self._data_valid:
            msg = "No data available (no succesful simulation run / dataset reload)"
            raise UsageError(msg)

        if simulator is None:
            simulator = self.simOpts._opts_container["simulator"]

        if simulator not in enums.SimulatorType.__dict__:
            msg = f"Specified Simulator is not valid. Valid simulators are: {enums.SimulatorType}; given simulator was: {simulator}"
            raise UsageError(msg)

        vcd_handle = "_".join([simulator, str(run_num)])
        vcd_file_name = self.path_for_sim_result_file(run_num)
        if vcd_handle not in self.vcd_handle:
            self.vcd_handle[vcd_handle] = VCDparser(vcd_file_name)
        return self.vcd_handle[vcd_handle]

    def path_for_sim_result_file(self, run_num):
        # Setup Simulation Result file names
        return os.path.join(self.simOpts.workingdir, f"{self.simOpts.fileprefix}_{run_num:04d}.vcd")

    def fetch_simdata(self, file_handle, name):
        """
        Load VCD signals and store values as dictionary

        :return: Dict of numpy arrays (keys are column titles, values are column values)
        :rtype: dict[numpy.array]
        """

        signal = r""
        if name.lower() == r"time":
            signals = file_handle.list_sigs()
            signal_dict = file_handle.parse_vcd(siglist=[signals[0]])
            """ :type : dict()"""

            for key in signal_dict:
                signal = [i[0] for i in signal_dict[key]["tv"]]
        elif r"_sig_time" in name:
            signal_dict = file_handle.parse_vcd(siglist=[name])
            """ :type : dict()"""

            for key in signal_dict:
                signal = [i[0] for i in signal_dict[key]["tv"]]
        else:
            signal_dict = file_handle.parse_vcd(siglist=[name])
            """ :type : dict()"""

            for key in signal_dict:
                signal = [i[1] for i in signal_dict[key]["tv"]]

        if signal in [""]:
            msg = f"No data found for signal:{name}"
            raise ValueError(msg)
        return np.array(signal)

    def write_sim_data_file(self, data=None, id=None):
        """
        Creates new sim data file with vcd file format
        """
        file = self.path_for_sim_result_file(run_num=id)
        time = data.pop("time")
        timescale, min_timestep = self.get_min_timestep(time)
        variable = {}
        # TODO: How to get min timestep from Simetrix and use this as timescale, now I'm using 1ps as timescale
        with VCDWriter(open(file, "w"), timescale=timescale, date="today") as writer:
            for name in data:
                variable[name] = writer.register_var("probes", name, "real")
            for n in range(1, time.__len__()):
                for var in variable:
                    writer.change(variable[var], time[n] / min_timestep, data[var][n])
            writer.close()

    def get_min_timestep(self, time_vector):
        # get min timesclae and timestep from a time vector in order to write vcd files
        min = np.min(np.diff(np.array(time_vector)))
        timescale = "1" + si_format(min).split(" ")[1]  # 1µ
        return timescale + "s", si_parse(timescale)


closeDataGroups = ApiSimetrix.closeDataGroups
