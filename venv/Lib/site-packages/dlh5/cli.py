from __future__ import annotations

import contextlib
import glob
import sys
from pathlib import Path
from typing import TYPE_CHECKING

import dlh5.errors

with contextlib.suppress(ImportError):
    from typing import Literal

import consolemenu
import fire
from rich import box, print
from rich.console import Console
from rich.pretty import pprint
from rich.table import Table

from dlh5 import DLH5
from dlh5.converters import any_to_dlh5
from dlh5.errors import MetadataExistsError
from dlh5.telemetry import track_feature
from dlh5.util import compress, uncompress

if TYPE_CHECKING:
    import pandas as pd
    from typing_extensions import Literal

console = Console()


def df_to_table(
    pandas_dataframe: pd.DataFrame,
    rich_table: Table,
    show_index: bool = True,
    index_name: str | None = None,
) -> Table:
    """Convert a pandas.DataFrame obj into a rich.Table obj.
    Args:
        pandas_dataframe (DataFrame): A Pandas DataFrame to be converted to a rich Table.
        rich_table (Table): A rich Table that should be populated by the DataFrame values.
        show_index (bool): Add a column with a row count to the table. Defaults to True.
        index_name (str, optional): The column name to give to the index column. Defaults to None, showing no value.
    Returns:
        Table: The rich Table instance passed, populated with the DataFrame values."""

    if show_index:
        index_name = str(index_name) if index_name else ""
        rich_table.add_column(index_name)

    for column in pandas_dataframe.columns:
        rich_table.add_column(str(column))

    for index, value_list in enumerate(pandas_dataframe.values.tolist()):
        row = [str(index)] if show_index else []
        row += [str(x) for x in value_list]
        rich_table.add_row(*row)

    return rich_table


def print_dataframe_as_table(df: pd.DataFrame):
    # Initiate a Table instance to be modified
    table = Table(show_header=True)

    # Modify the table instance to have the data from the DataFrame
    if len(df.columns) > 20:
        print(f"Showing only the first 20 out of {len(df.columns)} columns!")
    df = df.iloc[:, :20]

    table = df_to_table(df, table)

    # Update the style of the table
    table.row_styles = ["none", "dim"]
    table.box = box.SIMPLE_HEAD

    if table.columns:
        console.print(table)
    else:
        console.print("[i]No data...[/i]")
    console.print("")


def find_files(pattern: str | None = None, maxitems: int = 20) -> tuple[list[str], bool]:
    files_iter = glob.glob(pattern, recursive=True) if isinstance(pattern, str) else Path(".").rglob("*.dlh5")

    files = []
    maxitems = int(maxitems)
    if maxitems <= 0:
        msg = "maxitems must be greater than 0!"
        raise ValueError(msg)
    for i, f in enumerate(files_iter):
        if Path(f).suffix.lower() == ".dlh5":
            files.append(str(f))
            if i == maxitems - 1:
                return files, True
    return files, False


class Describe:
    def __init__(
        self,
        file: str | None = None,
    ):
        """

        :param file: A path or glob-style pattern to DLH5 files
            (see https://docs.python.org/3.11/library/glob.html#glob.glob).

            If multiple files are found, a selection dialog is shown.
        """
        files, more = find_files(pattern=file, maxitems=20)
        if more:
            print("Showing only the first 20 files...")

        if len(files) == 1:
            self._file = Path(files[0])
        elif len(files) > 1:
            selection = consolemenu.SelectionMenu.get_selection(
                files, title="Select a DLH5 file to describe", show_exit_option=False
            )
            self._file = Path(files[selection])
        else:
            if isinstance(file, str):
                msg = f"No DLH5 files found with given pattern {file!r}"
                raise FileNotFoundError(msg)

            msg = (
                f"Could not find any DLH5 files in current working directory or "
                f"child directories of {Path('.').absolute()}"
            )
            raise FileNotFoundError(msg)

        print(f"Describing DLH5 file: {self._file} ({self._file.absolute()})")
        self._d = DLH5(self._file, mode=DLH5.Mode.ReadOnly)

    def __del__(self):
        if hasattr(self, "_d"):
            self._d.close(skip_index=True)

    def file(self):
        """
        Describes a DLH5 file (file metadata, operating conditions, scalar results, group metadata)
        """
        groups = self._d.file_list_groups()
        if len(groups):
            print(f"Groups: {len(groups)} [{groups[0]}...{groups[-1]}]")
        else:
            print("Groups: 0")
        print("File-level Metadata:")
        pprint(self._d.file_get_metadata())
        print("Operating Conditions:")
        print_dataframe_as_table(self._d.get_index_operating_conditions().as_dataframe())
        print("Scalar Results:")
        print_dataframe_as_table(self._d.get_index_results().as_dataframe())
        print("Group Metadata:")
        self.group_metadata()

    def group(self, gid: int):
        """
        Describes a DLH5 group (group metadata, operating conditions, channel results)
        """
        group = self._d.file_get_group(gid)
        print(f"Group: {gid}")
        print("  Metadata:")
        pprint(self._d.group_get_metadata(group))
        print("  Operating Conditions:")
        pprint(self._d.group_get_operating_conditions(group))
        print("  Channels:")
        for ch in self._d.list_channels(gid):
            data, meta = self._d.group_get_channel(gid, ch)
            print(f"    {ch} [type: {meta['dtype']}]: {repr(data)[:100]}")
            print(f"      Metadata: {meta}]")

    def parameters(self):
        """
        Prints the operating conditions as table (first 20 columns).
        """
        print_dataframe_as_table(self._d.get_index_operating_conditions().as_dataframe())

    def results(self):
        """
        Prints the scalar (numeric/string-typed) results as table (first 20 columns)
        """
        print_dataframe_as_table(self._d.get_index_results().as_dataframe())

    def group_metadata(self):
        """
        Prints the group metadata as table (first 20 columns)
        """
        print_dataframe_as_table(self._d.get_index_metadata().as_dataframe())


class Merge:
    def many(
        self,
        target: str,
        *pattern: str,
        extlink: Literal["no", "abs", "rel"] = "no",
        force: bool = True,
        strategy: Literal["append", "merge_by_opcond"] = "append",
    ):
        """
        Takes an iterable of DLH5 files and merges them one by one into a target DLH5 file on disk.

        The first file's metadata will act as the basis, but other files may add new metadata in the merge process if it
        does not exist in the target.

        Merging is done by appending the groups of the source files after the last group of the target file,
        e.g. ``[0,1,2] + [0,1,2] = [0,1,2,3,4,5]``.

        Example:

            dlh5 merge many target.dlh5 "parts/*.dlh5" -e abs --force

        :param target: A file where all DLH5 files are merged into. Must not exist, unless ``force`` is set to True
        :param pattern: An iterable of DLH5 files to merge. Must contain at least one item.
            Paths may be glob-style patterns (see https://docs.python.org/3.11/library/glob.html#glob.glob).
        :param force: If True and ``target`` exists, it will be overwritten.
        :param extlink: Control how the groups of the source files are put into the target file.

            ``"no"``
                Copy groups into target file.

            ``"rel"``
                Link groups with relative links. This is typically used if the merged file should act as "access layer"
                for multiple source files.

                For the target file being readable after merging,
                the source files have to be kept relative to the target file.

            ``"abs"``
                Link groups with absolute links. This is typically used if the merged file should act as "access layer"
                for multiple source files.

                For the target file being readable after merging,
                the source files must not be to moved after merging, the target file may.
        :param strategy: The merge strategy to use. Can be either ``"append"`` or ``"merge_by_opcond"``.

            ``"append"`` means that the groups of the source files are appended after the last group of the target file.

            ``"merge_by_opcond"`` means that the groups of the target files are replaced by groups of the source files
            by matching the operating conditions. If no group with the same operating conditions is found, a new group
            is created.
        """
        source_files = []
        for pat in pattern:
            for match in glob.glob(pat, recursive=True):
                match_ = Path(match)
                if match_.suffix.lower() == ".dlh5":
                    source_files.append(str(match_.absolute()))

        target_ = Path(target)
        if target_.exists() and force:
            target_.unlink()

        print("Merging files:\n" + "\n  ".join(source_files))
        result = DLH5.merge(target=target_, files=source_files, extlink=extlink, strategy=strategy)
        return result.absolute()

    def into(
        self,
        target: str,
        source: str,
        extlink: Literal["no", "abs", "rel"] = "no",
        overwrite: bool = False,
        strategy: Literal["append", "merge_by_opcond"] = "append",
    ):
        """
        Merges the DLH5 file ``source`` into ``target``.

        The first file's metadata will act as the basis, but other files may add new metadata in the merge process if it
        does not exist in the target.

        Merging is done by appending the groups of the source files after the last group of the target file,
        e.g. ``[0,1,2] + [0,1,2] = [0,1,2,3,4,5]``.

        Example:

            dlh5 merge into target.dlh5 source.dlh5 -e abs -o False

        :param target: A file where the source DLH5 file is merged into. Must not exist, unless ``force`` is set to True
        :param source: A DLH5 file to merge.
        :param overwrite: If True, metadata and static text data from 'source' will overwrite equally named
            keys in 'target'.
        :param extlink: Control how the groups of the source files are put into the target file.

            ``"no"``
                Copy groups into target file.

            ``"rel"``
                Link groups with relative links. This is typically used if the merged file should act as "access layer"
                for multiple source files.

                For the target file being readable after merging,
                the source files have to be kept relative to the target file.

            ``"abs"``
                Link groups with absolute links. This is typically used if the merged file should act as "access layer"
                for multiple source files.

                For the target file being readable after merging,
                the source files must not be to moved after merging, the target file may.

        :param strategy: The merge strategy to use. Can be either ``"append"`` or ``"merge_by_opcond"``.

            ``"append"`` means that the groups of the source files are appended after the last group of the target file.

            ``"merge_by_opcond"`` means that the groups of the target files are replaced by groups of the source files
            by matching the operating conditions. If no group with the same operating conditions is found, a new group
            is created.
        """
        DLH5.merge_into(
            merge_target=Path(target), merge_source=source, extlink=extlink, overwrite=overwrite, strategy=strategy
        )


class Convert:
    def detect(self, source: str, dest: str | None = None, **kwargs):
        """
        Converts an input file into DLH5. Based on file extension and internal content, the appropriate converter is
        used, e.g. XVP-MAT, XVP-FLEX, PS-CV-MAT, ATV-SC-TDMS.

        Additional keyword arguments are passed on to ``DLH5.__init__``.

        Example:

            dlh5 convert detect source.mat
            dlh5 convert detect source.mat --dest out.dlh5
            dlh5 convert detect source.tdms --dest outdir
            dlh5 convert detect --source source.mat --dest out.dlh5
            dlh5 convert detect source.mat --zip True --zip-inplace False

        :param source: The source result file.
        :param dest: The destination where the generated file will be written.
            Depending on the converter, this can be a file or a directory.
            If omitted, the source file name or directory will be used as a basis.
        """
        return any_to_dlh5(src=source, dst=dest, **kwargs)

    def xvpmat(self, source: str, dest: str | None = None, **kwargs):
        """
        Converts an XVP mat result file to DLH5.

        Additional keyword arguments are passed on to ``DLH5.__init__``.

        Example:

            dlh5 convert xvpmat source.mat
            dlh5 convert xvpmat source.mat --dest out.dlh5
            dlh5 convert xvpmat --source source.mat --dest out.dlh5
            dlh5 convert xvpmat source.mat  --zip True --zip-inplace False

        :param source: The source XVP mat result file.
        :param dest: The destination where the generated file will be written.
            If omitted, the source file name will be used with its suffix changed to ".dlh5".
        """
        from dlh5.converters import xvpmat_to_dlh5

        return xvpmat_to_dlh5(src=source, dst=dest, **kwargs)

    def pscvmat(self, source: str, dest: str | None = None, **kwargs):
        """
        Converts an PS CV MAT result file to DLH5.

        Additional keyword arguments are passed on to ``DLH5.__init__``.

        Example:

            dlh5 convert pscvmat source.mat
            dlh5 convert pscvmat source.mat --dest out.dlh5
            dlh5 convert pscvmat --source source.mat --dest out.dlh5

        :param source: The source PS CV MAT result file.
        :param dest: The destination where the generated file will be written.
            If omitted, the source file name will be used with its suffix changed to ".dlh5".
        """
        from dlh5.converters import pscvmat_to_dlh5

        return pscvmat_to_dlh5(src=source, dst=dest, **kwargs)

    def atvsctdms(self, source: str, dest: str | None = None, **kwargs):
        """
        Converts an ATV SC TDMS result file to multiple DLH5 files (one for each test)

        Additional keyword arguments are passed on to ``DLH5.__init__``.

        Example:

            dlh5 convert atvsctdms source.tdms
            dlh5 convert atvsctdms source.tdms --dest outdir
            dlh5 convert atvsctdms --source source.tdms --dest outdir

        :param source: The source ATV SC TDMS result file.
        :param dest: The destination folder where the generated files will be written.
            If omitted, the source file directory will be used.
        """
        from dlh5.converters import atvsc_tdms_to_dlh5

        return atvsc_tdms_to_dlh5(src=source, dst_dir=dest, **kwargs)


class Cli:
    describe = Describe
    merge = Merge
    convert = Convert

    def upload(
        self,
        pattern: str,
        project: str,
        metadata: dict | None = None,
        timeout: int = 0,
        credentials: dict | None = None,
        offline: bool = False,
    ):
        """
        Uploads DLH5 files that match the pattern and explodes them online.

        Examples::

            dlh5 upload "examples/examplefile.dlh5" PYVECO  # bare minimum
            dlh5 upload "examples/examplefile.dlh5" PYVECO -m "{'test':123}" -t 0 --offline=False

        :param pattern: A glob-style wildcard pattern (see https://docs.python.org/3.11/library/glob.html#glob.glob)
            that matches DLH5 files, e.g. "**/*.dlh5"
        :param project: The R&D Datalake project to upload to
        :param metadata: A dictionary of additional metadata to add
        :param timeout: If > 0, waits for the explosion to be done (in seconds).
        :param offline: If True, explode artifact offline.
        :param credentials: Dictionary to pass the service user credentials for basic auth, e.g.

            {
                "username": "some_user"
                "password": "**********"
            }
        """
        if metadata is not None and not isinstance(metadata, dict):
            msg = f"Wrong input for metadata: {metadata!r}"
            raise ValueError(msg)

        try:
            from datacater.clients.datacater_client import DataCaterClient
        except ImportError:
            msg = (
                "Could not import datacater! Make sure you installed it, e.g. via PIP:\n"
                "pip install ifx-datacater --index-url "
                "https://artifactory.intra.infineon.com/artifactory/api/pypi/pypi-pyverify-vir/simple"
            )
            raise ImportError(msg) from None

        files = [Path(f) for f in glob.glob(pattern, recursive=True)]
        if not len(files):
            msg = f"Found no matching files for pattern {pattern!r}!"
            raise FileNotFoundError(msg)

        print("Uploading files:\n  " + "\n  ".join(map(str, files)))
        c = DataCaterClient(project_key=project, datalake_auth_credentials=credentials or {})
        jobinfo = c.upload_dlh5(
            *files, additional_metadata=metadata or {}, workers=1, explode_offline=bool(offline), timeout=int(timeout)
        )
        print("Job Information:")
        return jobinfo

    def set(self, *args, pattern: str | None = None, maxitems: int = 20, confirm: bool = True, overwrite: bool = True):
        """
        Updates file-level metadata on all found DLH5 files.

        Examples::

            dlh5 set key1 123  # bare minimum
            dlh5 set key1 123 --pattern **
            dlh5 set key1 123 key2 "foo" -p ** -m=1 --noconfirm --overwrite False

        :param args: Key values pairs of metadata items. Keys are converted to string, values to float or string.
        :param pattern: A glob-style wildcard pattern (see https://docs.python.org/3.11/library/glob.html#glob.glob)
            that matches DLH5 files, e.g. "**/*.dlh5".

            If omitted, up to ``maxitems`` items are auto-discovered recursively from your current
            working directory.
        :param maxitems: Max number of items to discover (limit the recursive file search)
        :param confirm: If True, let user confirm the action after listing the files to be modified.
        :param overwrite: If True, existing metadata keys will be overwritten, else a notification is printed for all
            keys that could not be set.
        """

        def convert(value):
            try:
                return float(value)
            except Exception:
                return str(value)

        if len(args) % 2 or not len(args):
            msg = "Number of positional args must be a multiple of 2 and minimum 2!"
            raise ValueError(msg)
        items = dict(zip(args[::2], args[1::2]))
        metadata = {str(k): convert(v) for k, v in items.items()}

        files, more = find_files(pattern=pattern, maxitems=maxitems)
        if more:
            print(f"More than maxitems ({maxitems}) found matching the given pattern ...")

        if not len(files):
            msg = f"No DLH5 files found with given pattern {pattern!r}"
            raise FileNotFoundError(msg)

        if confirm:
            print(f"Would update metadata {metadata} on following files:\n  " + "\n  ".join(files))
            answer = None
            while answer not in ("y", "n", ""):
                try:
                    answer = input("Continue? Y,n ").lower().strip()
                except KeyboardInterrupt:
                    return
            if answer == "n":
                return
        else:
            print(f"Updating metadata {metadata} on following files:\n  " + "\n  ".join(files))

        for f in files:
            with DLH5(f, DLH5.Mode.Append) as d:
                for k, v in metadata.items():
                    try:
                        d.file_add_metadata(k, v, overwrite=overwrite)
                    except MetadataExistsError:
                        print(f"Failed setting metadata {k}={v!r} (key already exists) on file {f!r}!")

    def verify(self, pattern: str | None = None, maxitems: int = 20):
        """
        Verifies if all external links to DLH5 files are still working.
        Useful after moving files around.

        Examples::

            dlh5 verify  # bare minimum
            dlh5 verify --pattern ** --maxitems 20

        :param pattern: A glob-style wildcard pattern (see https://docs.python.org/3.11/library/glob.html#glob.glob)
            that matches DLH5 files, e.g. "**".

            If omitted, up to ``maxitems`` items are auto-discovered recursively from your current
            working directory.
        :param maxitems: Max number of items to discover (limit the recursive file search)
        """
        files, more = find_files(pattern=pattern, maxitems=maxitems)
        if more:
            print(f"More than maxitems ({maxitems}) found matching the given pattern ...")

        if not len(files):
            msg = f"No DLH5 files found with given pattern {pattern!r}"
            raise FileNotFoundError(msg)

        for f in files:
            with DLH5(f, DLH5.Mode.ReadOnly) as d:
                try:
                    d.verify_external_links()
                    print(f"[bold green]  OK  [/bold green] {f}")
                except dlh5.errors.BrokenExternalLinkError as e:
                    print(f"[bold red]BROKEN[/bold red] {f}: {e}")

    def compress(
        self, pattern: str | None = None, maxitems: int = 20, inplace: bool = False, opts: int | dict | None = None
    ):
        """
        Compress files. Skipped if already compressed (file modification dates are compared).


        Examples::

            dlh5 compress  # bare minimum
            dlh5 compress --pattern ** --maxitems 20

        :param pattern: A glob-style wildcard pattern (see https://docs.python.org/3.11/library/glob.html#glob.glob)
            that matches DLH5 files, e.g. "**".

            If omitted, up to ``maxitems`` items are auto-discovered recursively from your current
            working directory.
        :param maxitems: Max number of items to discover (limit the recursive file search)
        :param inplace: Replace original file by the compressed version.
        :param opts: Keyword arguments that are passed to :class:`zipfile.ZipFile`
        """
        files, more = find_files(pattern=pattern, maxitems=maxitems)
        if more:
            print(f"More than maxitems ({maxitems}) found matching the given pattern ...")

        if not len(files):
            msg = f"No DLH5 files found with given pattern {pattern!r}"
            raise FileNotFoundError(msg)

        ONEMB = 1024 * 1024

        for f in files:
            size_before = Path(f).stat().st_size / ONEMB
            compressed = compress(f, inplace=inplace, opts=opts)
            size_after = Path(compressed).stat().st_size / ONEMB
            print(
                f"Compressed file {f}[{size_before:.3f}MB] to {compressed}[{size_after:.3f}MB]. "
                f"Size reduction: {100 - (size_after / size_before) * 100:.1f}%"
            )

    def uncompress(self, pattern: str | None = None, maxitems: int = 20, inplace: bool = True):
        """
        Uncompress files. Skipped if already uncompressed (file modification dates are compared).

        Examples::

            dlh5 uncompress  # bare minimum
            dlh5 uncompress --pattern ** --maxitems 20

        :param pattern: A glob-style wildcard pattern (see https://docs.python.org/3.11/library/glob.html#glob.glob)
            that matches DLH5 files, e.g. "**".

            If omitted, up to ``maxitems`` items are auto-discovered recursively from your current
            working directory.
        :param maxitems: Max number of items to discover (limit the recursive file search)
        :param inplace: Replace compressed file by the uncompressed version.
        """
        files, more = find_files(pattern=pattern, maxitems=maxitems)
        if more:
            print(f"More than maxitems ({maxitems}) found matching the given pattern ...")

        if not len(files):
            msg = f"No DLH5 files found with given pattern {pattern!r}"
            raise FileNotFoundError(msg)

        for f in files:
            uncompressed = uncompress(f, inplace=inplace)
            print(f"Uncompressed file {f} to {uncompressed}.")


def main(command=None):
    if len(sys.argv) >= 2:
        files = [Path(arg) for arg in sys.argv[1:]]
        all_inputs_are_files = all(file.is_file() for file in files)
        if all_inputs_are_files:
            track_feature("cli_convert_any")
            error = False
            for file in files:
                if file.suffix.lower() == ".dlh5":
                    continue
                try:
                    converted = any_to_dlh5(file)
                    print(f"Converted {str(file)!r} to {str(converted)!r}")
                except Exception as e:
                    print(f"Error converting file {str(file)!r}: {e}")
                    error = True
            if error:
                input("Error(s) occurred during conversion, please see above. Press Enter to continue...")
            return

    track_feature("cli")
    fire.Fire(component=Cli, name="dlh5", command=command)


if __name__ == "__main__":
    main()
