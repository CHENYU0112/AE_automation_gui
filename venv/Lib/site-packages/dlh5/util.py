from __future__ import annotations

import codecs
import datetime
import io
import re
import shutil
import zipfile
from json import JSONDecodeError, dumps, loads
from pathlib import Path
from typing import TYPE_CHECKING, Any

import numpy as np

from .errors import MetadataExistsError, UnsupportedDataTypeError

if TYPE_CHECKING:
    from h5py import Dataset, Group
    from h5py import File as h5pyFILE


def node_set_attribute(node: h5pyFILE | (Group | Dataset), key: str, value: Any, overwrite: bool = True):
    key = to_safe_key(key)
    if key in node.attrs and not overwrite:
        msg = f"Metadata key {key} already exists!"
        raise MetadataExistsError(msg)
    if isinstance(value, (complex, bytes, bytearray)):
        msg = f"Type {type(value)} not supported!"
        raise UnsupportedDataTypeError(msg)
    if isinstance(value, (list, set, tuple, dict)) or value is None:
        value = dumps(value, default=json_default_serializer)
    try:
        node.attrs[key] = value
    except TypeError:
        node.attrs[key] = dumps(value, default=json_default_serializer)


def decode_attr(value):
    try:
        return loads(value)
    except (JSONDecodeError, TypeError):
        if isinstance(value, np.int_):
            return int(value)
        if isinstance(value, np.float_):
            return float(value)
        if isinstance(value, np.bool_):
            return bool(value)
        return value


def node_get_attribute(node: h5pyFILE | (Group | Dataset), key: str | None):
    if key is None:
        attr = {k: decode_attr(v) for k, v in node.attrs.items()}
    else:
        try:
            raw = node.attrs[key]
            attr = decode_attr(raw)
        except KeyError:
            msg = f"There is no attribute named {key}!"
            raise KeyError(msg) from None
    return attr


def exists_encoding(enc: str):
    try:
        codecs.lookup(enc)
    except LookupError:
        return False
    return True


def to_safe_key(key: str) -> str:
    return key.replace("/", "_")


def json_default_serializer(value: Any):
    if isinstance(value, (np.integer, np.int_)):
        return int(value)
    if isinstance(value, (np.complexfloating,)):
        return str(value)
    if isinstance(value, (np.bool_,)):
        return bool(value)
    if isinstance(value, (datetime.datetime,)):
        return value.isoformat()
    msg = f"Unsupported type {type(value)} of value {value}"
    raise TypeError(msg)


def check_for_nextcloud_monitoring(filepath: str | (Path | io.FileIO)):
    """
    File sync tools like the Nextcloud desktop client are known to interfere with creation of DLH5 files.

    This function traverses the filepath up in search of files specific to nextcloud.

    :param filepath: The path to the DLH5 file, or an open file handle.
    :raises RuntimeError: if the filepath is part of a folder structure monitored by the Nextcloud client.
    """

    filepath = Path(filepath.name) if isinstance(filepath, io.FileIO) else Path(filepath)

    nextcloud_indicator_regex = re.compile(r"^\.sync_[a-z0-9]*")
    for parent in filepath.parents:
        db_files = [file.name for file in parent.glob("*.db*")]
        nextcloud_detected = bool([filename for filename in db_files if nextcloud_indicator_regex.match(filename)])

        if nextcloud_detected:
            nextcloud_sync_folder = parent
            msg = (
                "DLH5 storage location is monitored by Nextcloud which is known to cause problems during DLH5 write "
                f"operations. Please choose a folder outside of this monitored folder: '{nextcloud_sync_folder}' for "
                f"'{filepath}'."
            )
            raise RuntimeError(msg)


def compress(file: Path | str, inplace: bool = False, opts: int | dict | None = None) -> Path:
    """
    Compress a file. Skipped if already compressed (file modification dates are compared).

    :param file: The file to compress
    :param inplace: Replace original file by the compressed version.
    :param opts: Keyword arguments that are passed to :class:`zipfile.ZipFile`
    :return: The path to the compressed file
    """
    if not isinstance(file, (str, Path)):
        msg = "'file' must be a str or Path instance!"
        raise TypeError(msg)
    file = Path(file)

    if opts is None:
        opts = {"compression": zipfile.ZIP_DEFLATED, "compresslevel": 1}
    elif isinstance(opts, int):
        opts = {"compression": zipfile.ZIP_DEFLATED, "compresslevel": opts}
    elif not isinstance(opts, dict):
        msg = "'opts' must be either an integer or a dict!"
        raise TypeError(msg)

    dst = file.with_name(file.stem.removesuffix(".uncompressed") + ".compressed" + file.suffix)

    src_mtime = file.stat().st_mtime_ns
    dst_mtime = dst.stat().st_mtime_ns if dst.exists() else 0
    if dst_mtime < src_mtime:
        with zipfile.ZipFile(dst, mode="w", **opts) as zip:
            zip.write(file, arcname="data")

    if inplace:
        file.unlink(missing_ok=False)
        dst = dst.rename(file)

    return dst


def uncompress(file: Path | str, inplace: bool = False) -> Path:
    """
    Uncompress a file. Skipped if already uncompressed (file modification dates are compared).

    :param file: The file to compress
    :param inplace: Replace compressed file by the uncompressed version.
    :return: The path to the compressed file
    """
    if not isinstance(file, (str, Path)):
        msg = "'file' must be a str or Path instance!"
        raise TypeError(msg)
    file = Path(file)

    if not zipfile.is_zipfile(file):
        return file

    dst = file.with_name(file.stem.removesuffix(".compressed") + ".uncompressed" + file.suffix)

    src_mtime = file.stat().st_mtime_ns
    dst_mtime = dst.stat().st_mtime_ns if dst.exists() else 0
    if dst_mtime < src_mtime:
        with zipfile.ZipFile(file, mode="r") as zip, zip.open("data") as fsrc, open(dst, "wb") as fdst:
            shutil.copyfileobj(fsrc, fdst)

    if inplace:
        file.unlink(missing_ok=False)
        dst = dst.rename(file)

    return dst


def elastic_friendly(obj: Any):
    """
    Recursively converts a dict to an Elastic-friendly representation,
    that only contains nested containers (dict, list) and datatypes of either float or string.
    """
    if not isinstance(obj, dict):
        return obj
    new_d = {}
    for k, v in obj.items():
        if v is None:
            continue
        if isinstance(v, dict):
            new_v = elastic_friendly(v)
        elif isinstance(v, list):
            new_v = [elastic_friendly(elem) for elem in v if elem is not None]
        elif isinstance(v, datetime.datetime):
            new_v = v.astimezone(datetime.timezone.utc).isoformat()
        elif isinstance(v, str):
            new_v = v
        else:
            try:
                new_v = float(v)
            except Exception:
                new_v = str(v)

        if isinstance(new_v, (list, dict)):
            if len(new_v) > 0:
                new_d[k] = new_v
        else:
            new_d[k] = new_v
    return new_d
