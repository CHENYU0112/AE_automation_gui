from __future__ import annotations

import json
from pathlib import Path

from pverify.core.util.json_encoder import CustomJSONEncoder


def dlh5_to_json(filepath_in: Path | str, filepath_out: Path | str | None = None, indent=2) -> Path:  # pragma: no cover
    """
    Creates a JSON file from DLH5. Only scalar results (numeric + string) will be contained.

    :param filepath_in: The file path to the result data to be converted
    :param filepath_out: The destination of the converted file.
                         If omitted it will be stored at the input file location with a different file suffix.
    :returns: The path to the converted file.
    """
    from pverify.core.io.pv_dlh5 import PyVerifyDLH5 as DLH5

    filepath_in = Path(filepath_in)
    if filepath_out is None:
        filepath_out = filepath_in.with_suffix(".xml")
    filepath_out = Path(filepath_out)
    filepath_out.parent.mkdir(parents=True, exist_ok=True)

    content = {"file_metadata": {}, "iterations": []}

    with DLH5(filepath_in, "r") as d:
        content["file_metadata"].update(d.file_get_metadata())

        for gid in d.file_list_groups():
            grp = d.file_get_group(gid)

            iteration_data = {
                "metadata": d.group_get_metadata(grp, None),
                "parameters": {},
                "results": {},
                "spec_eval_results": [],
            }

            for pname, pvalue in d.group_get_operating_conditions(grp, None).items():
                iteration_data["parameters"][pname] = {"value": pvalue[0], "unit": pvalue[1]}

            for ch in d.list_numeric_channels(grp) + d.list_string_channels(grp):
                data, metadata = d.group_get_channel(grp, ch)
                if metadata.get("subtype", "") != "specification_result":
                    iteration_data["results"][ch] = {
                        "value": data,
                        "unit": metadata.get("unit", ""),
                        "meta_data": metadata,
                    }
                else:
                    result = metadata["specresult"]

                    result_dictified = {
                        "upper_limit_result": result["result_upper_thres"],
                        "lower_limit_result": result["result_lower_thres"],
                        "overall_result": result["overall_result"],
                        "error_message": result.get("error_msg", "N.A."),
                    }
                    specification = result["specification"]
                    item = {
                        "result": result_dictified,
                        "identifier": specification["reference_output"],
                        "alias": specification["alias"],
                        "conditions": specification["conditions"],
                        "reference": specification["reference"],
                        "upper_limit": specification["upper_thres"],
                        "lower_limit": specification["lower_thres"],
                        "x_range": specification["x_range"],
                        "uid": specification["uid"],
                    }

                    iteration_data["spec_eval_results"].append(item)

            content["iterations"].append(iteration_data)

    with open(filepath_out, "w") as f:
        json.dump(content, f, indent=indent, cls=CustomJSONEncoder)

    return filepath_out
