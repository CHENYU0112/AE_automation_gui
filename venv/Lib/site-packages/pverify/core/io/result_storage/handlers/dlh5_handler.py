from __future__ import annotations

import os
import re
from numbers import Number
from pathlib import Path
from typing import *
from typing import TYPE_CHECKING

import numpy as np

from pverify import Waveform
from pverify.core.internals.logging_util import get_test_logger
from pverify.core.internals.unit import ScalarUnit
from pverify.core.io.pv_dlh5 import PyVerifyDLH5 as DLH5
from pverify.core.io.result_storage.result_handler import ResultHandler

if TYPE_CHECKING:
    from pverify.core.internals.specification import SpecificationResult


def skip_if_h5_none(f):
    def wrapped(self, *args, **kw):
        if self._h5 is not None:
            return f(self, *args, **kw)
        return None

    return wrapped


class dlh5_handler(ResultHandler):
    """
    Creates a DLH5 result file
    """

    def __init__(self):
        super().__init__()
        self.filename = "results"

        self._h5: DLH5 = None

        self._iteration_metadata = {}
        self._iteration_parameters = {}
        self._iteration_results = {}
        self._iteration_spec_eval_results = []
        self._current_index = 0

        self._iteration_indexes = []

    def initialize(self):
        self.filename = self.config.get("filename", self.filename)

        file = self.resultdir / f"{self.filename}.dlh5"
        if file.exists():
            os.remove(file)
        self._h5 = DLH5(
            file=file,
            mode=DLH5.Mode.Append,
            auto_create_index=False,
            logger=get_test_logger(),
            lock_file_tmo=20,
        )

    @skip_if_h5_none
    def update_file_metadata(self, key: str, value: Any):
        with self._h5:
            self._h5.file_add_metadata(key, value)

    @skip_if_h5_none
    def add_static_string_data(self, key: str, string_data: str):
        with self._h5:
            self._h5.static_add_text_data(key, string_data)

    @skip_if_h5_none
    def new_iteration(self, index: int):
        self._iteration_metadata.clear()
        self._iteration_parameters.clear()
        self._iteration_results.clear()
        self._iteration_spec_eval_results.clear()
        self._current_index = index

    @skip_if_h5_none
    def update_iteration_metadata(self, key: str, value: Any, unit: str = ""):
        self._iteration_metadata[key] = value

    @skip_if_h5_none
    def update_iteration_parameter(self, key: str, value: Any, unit: str = ""):
        self._iteration_parameters[key] = (value, unit)

    @skip_if_h5_none
    def update_iteration_result(self, key: str, value: Any, unit: str = "", meta_data: Dict[str, Any] = None):
        self._iteration_results[key] = [value, unit, meta_data]

    @skip_if_h5_none
    def update_iteration_result_metadata(self, result_name: str, key: str, value: Any):
        if result_name in self._iteration_results:
            if isinstance(self._iteration_results[result_name][2], dict):
                self._iteration_results[result_name][2][key] = value
            else:
                self._iteration_results[result_name][2] = {key: value}
        else:
            self._log.warning(f"Cannot update metadata on unknown iteration result {result_name!r}!")

    @skip_if_h5_none
    def add_iteration_spec_eval_result(
        self,
        result: SpecificationResult,
    ):
        if result in self._iteration_spec_eval_results:
            self._iteration_spec_eval_results.remove(result)
        self._iteration_spec_eval_results.append(result)

    @skip_if_h5_none
    def commit_iteration(self):
        iteration_index = self._current_index
        self._iteration_indexes.append(iteration_index)

        with self._h5:
            grp = self._h5.file_require_group(iteration_index)

            for p in self._iteration_parameters:
                value, unit = self._iteration_parameters[p]
                self._h5.group_add_operating_condition(
                    grp,
                    key=p,
                    value=value,
                    unit=unit,
                )

            for m in self._iteration_metadata:
                value = self._iteration_metadata[m]
                self._h5.group_add_metadata(
                    grp,
                    key=m,
                    value=value,
                )

            for o in self._iteration_results:
                data, unit, meta_data = self._iteration_results[o]
                # dtype is a DLH5 internal metadata key which is determined by the data type automatically.
                # Remove it here to avoid mismatch or confusion
                meta_data.pop("dtype", None)
                encoding = meta_data.pop("encoding", None)  # Will be added by following function again

                if isinstance(data, Path):
                    if hasattr(self._h5, "group_add_file_channel"):
                        self._h5.group_add_file_channel(grp, o, data, meta_data=meta_data)
                    else:
                        self._h5.group_add_string_channel(grp, o, str(data), encoding, meta_data=meta_data)
                elif isinstance(data, str):
                    self._h5.group_add_string_channel(grp, o, data, encoding or "utf-8", meta_data=meta_data)
                elif isinstance(data, (bytes, bytearray)):
                    self._h5.group_add_string_channel(grp, o, data, encoding, meta_data=meta_data)
                elif isinstance(data, Waveform):
                    if not data.is_empty:
                        for k in ("xunit", "yunit"):
                            # Already contained in waveform metadata
                            if k in meta_data:
                                del meta_data[k]
                        if ScalarUnit.is_waveform_unit(unit):
                            yunit, xunit = re.findall(r"(.*)\((.*)\)", unit)[0]
                        else:
                            yunit, xunit = data.getMeta("yunit", ""), data.getMeta("xunit", "")
                        self._h5.group_add_waveform_channel(
                            grp,
                            o,
                            y_data=data.data,
                            x_data=data.time,
                            unit_x=xunit,
                            unit_y=yunit,
                            meta_data=meta_data,
                        )
                elif isinstance(data, (int, np.int_, float, np.float64, Number)):
                    self._h5.group_add_numeric_channel(grp, o, data, unit=unit, meta_data=meta_data)
                elif isinstance(data, np.ndarray):
                    self._h5.group_add_array_channel(grp, o, data, unit=unit, meta_data=meta_data)
                elif data is None:
                    pass

            specresult: SpecificationResult
            for specresult in self._iteration_spec_eval_results:
                self._h5.group_add_string_channel(
                    grp,
                    specresult.specification.alias,
                    specresult.overall_result.value,
                    meta_data={"specresult": specresult.for_json(), "subtype": "specification_result"},
                )

    @skip_if_h5_none
    def commit_file(self):
        with self._h5:
            self._h5.create_indexes()
        file = self._h5.fileio
        self._h5 = None
        return file
