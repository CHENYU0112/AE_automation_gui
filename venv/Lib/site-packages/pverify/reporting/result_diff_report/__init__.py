from __future__ import annotations

import json
import typing
from collections import defaultdict
from pathlib import Path

import jinja2

from pverify.core.io.pv_dlh5 import PyVerifyDLH5


def to_str(value) -> str:
    if isinstance(value, float):
        return f"{value:.3e}"
    return str(value)


def load_json(path):
    with open(path) as f:
        d = json.load(f)

    meta = d["file_metadata"]
    param = defaultdict(list)
    results = defaultdict(list)
    spec = defaultdict(list)
    index = []

    for iteration in d["iterations"]:
        for k, v in iteration["parameters"].items():
            param[k].append(v["value"])
        for k, v in iteration["results"].items():
            if v["meta_data"]["dtype"] != "waveform":
                results[k].append((to_str(v["value"]), v["meta_data"]["spec_status"]))
        for v in iteration["spec_eval_results"]:
            res = v["result"]
            if res["overall_result"].lower() == "fail":
                spec[v["alias"]].append(
                    f'{res["overall_result"]} '
                    f'(&uarr;{res["upper_limit_result"][0]} &darr;{res["lower_limit_result"][0]})'
                )
            else:
                spec[v["alias"]].append(f'{res["overall_result"]}')
        iindex = iteration["metadata"]["PyVerifyIterationIndex"]
        if isinstance(iindex, dict):
            iindex = iindex["value"]  # Keep compat. to old interface, we don't store units on metadata anymore
        index.append(iindex)

    return meta, index, param, results, spec


def load_dlh5(path):
    with PyVerifyDLH5(Path(path), "r") as f:
        index = f.get_index_operating_conditions().get_group_ids()
        meta = f.file_get_metadata()

        # Merge in unique metadata of iterations
        itermeta = f.get_index_metadata().as_dataframe()
        itermeta_unique = itermeta.loc[0, itermeta.nunique()[itermeta.nunique() == 1].index.to_list()].to_dict()
        meta.update(itermeta_unique)

        param = f.get_index_operating_conditions().as_dataframe().to_dict(orient="list")

        results = defaultdict(list)
        spec = defaultdict(list)

        for gid in f.file_list_groups():
            grp = f.file_get_group(gid)
            for ch in f.list_numeric_channels(grp) + f.list_string_channels(grp):
                data, metadata = f.group_get_channel(grp, ch)
                if metadata.get("subtype", "") == "specification_result":
                    res = metadata["specresult"]
                    if res["overall_result"].lower() == "fail":
                        spec[ch].append(
                            f'{res["overall_result"]} '
                            f'(&uarr;{res["result_upper_thres"][0]} &darr;{res["result_lower_thres"][0]})'
                        )
                    else:
                        spec[ch].append(f'{res["overall_result"]}')
                else:
                    results[ch].append((to_str(data), metadata["spec_status"]))

        return meta, index, param, results, spec


def color(text: str, color: str) -> str:
    return f"""<span style="color: {color}">{text}</span>"""


def color_pf(item: str | tuple[str, str]) -> str:
    if isinstance(item, str):
        text = pf = item
    else:
        text, pf = item
    if "pass" in pf.lower():
        return color(text, "green")
    if "fail" in pf.lower():
        return color(text, "red")
    if any(x in pf.lower() for x in ["unknown", "error"]):
        return color(text, "orange")
    return text


def dict_get_item(dikt, key, idx):
    if key not in dikt:
        return "MISSING"
    try:
        return dikt[key][idx]
    except Exception:
        return "N.A."


def get_loader(file: Path) -> typing.Callable:
    file = Path(file)
    ext = file.suffix.lower()
    if "dlh5" in ext:
        return load_dlh5
    if "json" in ext:
        return load_json
    msg = f"Not implemented for file extension {file.suffix}!"
    raise NotImplementedError(msg)


def result_diff_report(output: str | Path, input_file1: str | Path, input_file2: str | Path | None = None):
    r"""
    Create an overview HTML report out of the json/DLH5 result file of a test execution.
    A second result file can be specified to create a diff-report between old and new executions.

    :param output: The target output file (\*.html)
    :param input_file1: A json/DLH5-result file of a PyVerify test execution
    :param input_file2: A second json/DLH5-result file of a PyVerify test execution.
                        The report will show the difference of both files.
    """
    loader = jinja2.FileSystemLoader(Path(__file__).with_name("template.html").as_posix())
    env = jinja2.Environment(
        loader=loader,
        trim_blocks=True,
    )
    template = env.get_template("")

    file1 = Path(input_file1)
    meta1, index1, param1, results1, spec1 = get_loader(file1)(file1)

    if input_file2 is not None:
        file2 = Path(input_file2)
        meta2, index2, param2, results2, spec2 = get_loader(file2)(file2)
    else:
        meta2, index2, param2, results2, spec2 = meta1, index1, param1, results1, spec1

    if param1 != param2 or index1 != index2:
        msg = "Index or parameter table is different thus cannot be merged!"
        raise ValueError(msg)

    index = index1
    param = param1

    static_param1 = [k for k, v in param1.items() if len(set(v)) == 1]
    static_param2 = [k for k, v in param1.items() if len(set(v)) == 1]
    static_params = {k: param1[k][0] for k in set(static_param1 + static_param2)}

    for p in static_params:
        del param1[p]
        if p in param2:
            del param2[p]

    resultnames = list(set(results1.keys()).union(set(results2.keys())))
    specnames = sorted(set(spec1.keys()).union(set(spec2.keys())))

    overview_table_header = [[], []]
    overview_table_header[0] = (
        ["Index"] + ["Parameter"] * len(param.keys()) + ["Result"] * len(resultnames) + ["Spec"] * len(specnames)
    )
    overview_table_header[1] = ["", *list(param.keys()), *list(resultnames), *list(specnames)]

    overview_table = []
    for i in index:
        row = [i] + [col[i] for col in param.values()]
        for rname in resultnames:
            old = dict_get_item(results1, rname, i)
            new = dict_get_item(results2, rname, i)
            if old == new:
                row.append(color_pf(old))
            else:
                row.append(f"{color_pf(old)}<br>&darr;<br>{color_pf(new)}")
        for sname in specnames:
            old = dict_get_item(spec1, sname, i)
            new = dict_get_item(spec2, sname, i)
            if old == new:
                row.append(color_pf(old))
            else:
                row.append(f"{color_pf(old)}<br>&darr;<br>{color_pf(new)}")

        overview_table.append(row)

    metadata_table = []
    for key in sorted(set(meta1.keys()).union(set(meta2.keys()))):
        old = meta1.get(key, "MISSING")
        new = meta2.get(key, "MISSING")
        if old == new:
            metadata_table.append((key, old))
        elif old == "MISSING":
            metadata_table.append((key, color(new, "orange")))
        else:
            metadata_table.append((key, f"{old}<br>&darr;<br>{color(new, 'orange')}"))

    if input_file2 is None:
        header2 = f"Test Case {meta1['PyVerifyTestCaseName']!r} - Class {meta1['PyVerifyTestClassName']!r}"
    else:
        header2 = (
            f"Comparison-Report between<br>"
            f"Test Case {meta1['PyVerifyTestCaseName']!r} - "
            f"Class {meta1['PyVerifyTestClassName']!r} of file {Path(input_file1).as_posix()!r}"
            "<br>and<br>"
            f"Test Case {meta2['PyVerifyTestCaseName']!r} - "
            f"Class {meta2['PyVerifyTestClassName']!r} of file {Path(input_file2).as_posix()!r}"
        )

    output = Path(output)
    output.parent.mkdir(parents=True, exist_ok=True)
    with open(output, "w") as f:
        f.write(
            template.render(
                title="PyVerify Result Overview" if input_file2 is None else "PyVerify Result Diff Report",
                header1="PyVerify Result Overview" if input_file2 is None else "PyVerify Result Diff Report",
                header2=header2,
                overview_table_header=overview_table_header,
                overview_table=overview_table,
                metadata_table=metadata_table,
                static_params=static_params,
            )
        )
